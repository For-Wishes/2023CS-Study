# 요구 페이징

- 가져오기 정책
    - 프로세스가 필요로 하는 데이터를 언제 메모리로 가져올지 결정하는 것
    - 프로세스가 요청할 때 메모리로 가져오는 방법이 일반적
        - 요구 페이징

## 요구 페이징의 개요

- 운영체제는 프로세스를 구성하는 모듈 중 필요한 모듈만 메모리에 올려 실행하고 나머지 모듈은 필요하다고 판단될 때 메모리로 불러옴
    - 메모리를 효율적으로 관리하기 위해
        - 가급적 적은 양의 프로세스만 유지
    - 응답속도 향상을 위해
        - 용량이 큰 프로세스를 전부 메모리로 가져와 실행하면 응답이 늦어질 수 있다
- 프로그램의 일부만 가져와 실행하고 사용자가 특정 기능을 요구할 때 해당 모듈을 메모리에 올리면 **메모리 절약**, **메모리의 효율적 관리**, **프로세스의 응답 속도 향상** 등이 효과를 볼 수 있다
- **요구 페이징**: 사용자가 요구할 때 해당 페이지를 메모리로 가져오는 것
- 미리 가져오기: 앞으로 필요할 것이라고 예상되는 페이지를 미리 가져오는 방식
    - ex) 캐시
    - 미리 가져온 데이터가 쓸모없을 경우 피해가 매우 크기 때문에 현대의 운영체제는 요구 페이징을 기본으로 사용

## 페이지 테이블 엔트리의 구조

- 가상 메모리 시스템에서 사용자의 프로세스는 물리 메모리와 스왑 영역 중 한 곳에 있다
- 페이지가 스왑 영역에 있는 경우
    1. 요구 페이징으로 인해 처음부터 물리 메모리에 올라가지 못한 경우
    2. 메모리가 꽉차서 스왑 영역으로 옮겨 온 경우
- 유효 비트: 페이지 테이블에 페이지가 메모리에 있는지, 스왑 영역에 있는지 표시

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1668599066882/DS_xgPbmN.png?auto=compress,format&format=webp)

- 페이지 테이블 엔트리(PTE)의 구성: 페이지 번호, 플래그 비트, 프레임 번호
- 페이지 번호: 직접 매핑에서는 필요 없지만, 연관 매핑에서는 필요
- 프레임 번호: 가상 주소의 해당 페이지가 어느 프레임에 있는지 알려줌
    - 메모리 관리자는 찾은 프레임 번호를 이용하여 가상 주소를 물리 주소로 변환
    - 주소 필드라고도 함
- 플래그 비트
    - **접근 비트(참조 비트)**
        - 페이지가 메모리에 올라온 후 사용한 적이 있는지 알려줌
        - 해당 메모리에 읽기나 실행 작업을 했다면 접근 비트가 1
    - **변경 비트(더티 비트)**
        - 페이지가 메모리에 올라온 후 데이터의 변경이 있었는지 알려줌
        - 해당 메모리에 쓰기나 추가 작업을 했다면 변경 비트가 1
    - **유효 비트(현재 비트)**
        - 페이지가 실제 메모리에 있는지를 나타냄
    - **읽기, 쓰기, 실행 비트(접근 권한 비트)**
        - 페이지에 대한 읽기 권한, 쓰기 권한, 실행 권한을 나타내는 비트
        - 읽기 권한이 없는 프로세스가 읽으려고 하거나 쓰기 권한이 없는 프로세스가 쓰려고 할때 접근 차단하는데 사용
    - 접근 비트와 변경 비트는 페이지가 메모리에 올라온 후 어떤 작업이 있었는지 알려주는 역할

## 페이지 부재

- 가상 메모리의 페이지 테이블에는 페이지가 물리 메모리에 있는지, 스왑 영역에 있는지 표시하기 위해 유효비트 사용
- 유효비트가 0일 때: 페이지가 메모리에 있으므로 주소 필드에 물리 메모리의 프레임 번호 저장
- 유효비트가 1일 때: 페이지가 스왑 영역에 있으므로 주소 필드에 스왑 영역 내 페이지 주소 저장

- **페이지 부재**: 프로세스가 페이지를 요청했을 때 그 페이지가 메모리에 없는 상황
- 페이지 부재가 발생하면 프로세스가 해당 페이지를 사용할 수 있도록 스왑 영역에서 물리 메모리로 옮겨져야 한다
- 페이지 부재가 발생했을 때 메모리 관리자의 작업
    - 프로세스가 페이지 3을 요청했는데 PTE 3의 유효 비트가 1이면 페이지 부재 발생
    - 주소 필드 값이 0이라면 페이지 3은 메모리에 없고 스왑 영역의 0번에 있음
    - 메모리 관리자는 스왑 영역의 0번에 있는 페이지를 메모리의 비어있는 프레임으로 가져온다(스왑인)
        - 그 프레임에 페이지가 들어오면 PTE 3의 유효비트는 0이 되고, 주소 필드 값은 그 프레임의 번호로 바뀐다
    - 빈 프레임이 없을 때는 메모리에 있는 프레임 중 하나를 스왑 영역으로 내보낸 후에야 해당 페이지를 가져올 수 있다
        - 페이지 교체 알고리즘에 의해 스왑 영역으로 보낼 대상 페이지 결정
- 메모리가 꽉 찬 상태에서 페이지 부재가 발생했을 때 발생하는 작업
    - 프로세스가 페이지를 요청했는데 그 페이지의 유효비트가 1이면 페이지 부재 발생
    - 메모리가 꽉 차 있는 상태이기 때문에 스왑 영역에 있는 페이지를 가져오기 위해 메모리의 페이지 중 하나를 스왑 영역으로 내보내고, 대상 페이지를 스왑 영역으로 옯긴다(스왑아웃)
        - 대상 페이지의 유효트가 1로, 주소 필드 값이 스왑 주소로 변함
    - 스왑 영역에 있던 페이지가 프레임으로 올라감(스왑인)
        - 그 페이지의 유효비트는 0으로, 주소 필드 값이 프레임의 주소로 바뀜

- 세그먼테이션 오류와 페이지 부재의 차이
    - 세그먼테이션 오류: 사용자의 프로세스가 주어진 메모리 공간을 벗어나거나 접근 권한이 없는 곳에 접근할 때 발생
        - 즉 사용자 프로세스에 의해 발생
        - 해당 프로세스를 강제 종료하여 해결
    - 페이지 부재: 해당 페이지가 물리 메모리에 없을 때 발생하는 오류
        - 사용자 프로세스와 무관

## 지역성

- 메모리가 꽉 차서 어떤 페이지를 스왑 영역으로 보낼 때는 되도록 앞으로 사용하지 않을 페이지를 쫓아내는 것이 좋음
- 페이지 교체 알고리즘이 쫓아낼 페이지를 찾을 때는 지역성을 바탕으로 함
- **지역성**: 기억장치에 접근하는 패턴이 메모리 전체에 고루 분포되는 것이 아니라 특정 영역에 집중되는 성질
    - 국부성, 집약성
- **공간의 지역성**
    - 현재 위치에서 가까운 데이터에 접근할 확률이 먼 거리에 있는 데이터에 접근할 확률보다 높다
- **시간의 지역성**
    - 현재를 기준으로 가장 가까운 시간에 접근한 데이터가 더 먼 시간에 접근한 데이터보다 사용될 확률이 높다
- **순차적 지역성**
    - 여러 작업이 순서대로 진행되는 경향이 있다
    - 일반적인 프로그래밍은 처음부터 마지막 순서로 진행되는 경향이 있다
- **캐시**는 지역성 이론을 사용하는 대표적인 장치
    - 시간적으로나 지역적으로 가까이 있는 데이터를 가져옴으로써 캐시 적중률을 높임
- 페이지 교체 알고리즘에서는 앞으로 적게 사용될 페이지를 대상 페이지로 선정함으로써 페이지 부재를 줄이고 컴퓨터의 성능을 높임

# 페이지 교체 알고리즘

## 페이지 알고리즘의 개요

- 스왑 영역으로 보낼 페이지를 결정
- 메모리에서 앞으로 사용할 가능성이 적은 페이지를 대상 페이지로 선정하여 페이지 부재를 줄이고 시스템의 성능 향상

### 페이지 교체 알고리즘

| 종류 | 알고리즘 | 특징 |
| --- | --- | --- |
| 간단한 알고리즘 | 무작위 | 무작위로 대상 페이지를 선정하여 스왑 영역으로 보낸다 |
|  | FIFO | 처음 메모리에 올라온 페이지를 스왑 영역으로 보낸다 |
| 이론적 알고리즘 | 최적 | 미래의 접근 패턴을 보고 대상 페이지를 선정하여 보냄 |
| 최적 근접 알고리즘 | LRU | 시간적으로 멀리 떨어진 페이지를 보냄 |
|  | LFU | 사용 빈도가 적은 페이지를 보냄 |
|  | NUR | 최근에 사용한 적이 없는 페이지를 보냄 |
|  | FIFO 변형 | FIFO 알고리즘을 변형하여 성능을 높임 |

### 페이지 교체 알고리즘의 성능 평가 기준

- 다양한 비교 방법이 있음
    1. 페이지 부재 횟수를 세어본다
    2. 페이지를 요청한 후 실제로 작업에 들어갈 때까지의 평균 대기 시간 측정
    3. 전체 작업에 걸리는 시간을 비교
- 페이지 교체 알고리즘은 성능 뿐만 아니라 유지 비용도 고려해야 한다
    - 성능이 뛰어나도 계산이 많이 필요하거나 메모리를 많이 차지한다면 좋은 알고리즘이 아님

## 무작위 페이지 교체 알고리즘

- 페이지 교체 알고리즘 중 가장 간단하게 구현 가능
- 대상 페이지를 특별한 로직 없이 무작위로 선정
- 지역성을 전혀 고려하지 않음
    - 자주 사용하는 페이지가 선정될 수도 있음
- 알고리즘의 성능이 좋지 않아 거의 사용되지 않는다

## FIFO 페이지 교체 알고리즘

- 시간상으로 메모리에 가장 먼저 들어온 페이지를 대상 페이지로 선정

![](https://yansigit.github.io/posts/페이지-교체-알고리즘/Untitled%202.png)

- 큐로 구현
    - 새로운 페이지는 항상 맨 아래 삽입
- 큐로 쉽게 구현할 수 있지만 먼저 들어온 페이지를 항상 스왑 영역으로 옮긴다
- 메모리에 올라온 시간만 고려하기 때문에 자주 사용되는 페이지가 스왑 영역으로 옮겨지기도 한다
- 무조건 오래된 페이지를 대상 페이지로 선정하여 성능이 떨어짐

## 최적 페이지 교체 알고리즘

![](https://yansigit.github.io/posts/페이지-교체-알고리즘/Untitled%203.png)

- 앞으로 사용하지 않을 페이지를 스왑 영역으로 옮긴다
- 메모리가 앞으로 사용할 페이지를 미리 살펴보고 페이지 교체 선정 시점부터 가장 멀리 있는 페이지를 대상 페이지로 선정
- 미래의 메모리 접근 패턴을 보고 대상 페이지를 결정하기 때문에 성능이 좋음
- 하지만 미래의 접근 패턴을 아는 것이 불가능하여 실제로는 구현할 수 없다
- 구현이 가능하면서도 성능이 최적 페이지 교체 알고리즘에 근접하는 알고리즘 개발
    - LRU, LFU, NUR
    - 과거의 테이블을 바탕으로 미래의 접근 패턴 추정
        - 최적 근접 알고리즘

## LRU 페이지 교체 알고리즘

- 최근 최소 사용 페이지 교체 알고리즘
- 메모리에 올라온 후 가장 오랫동안 사용되지 않은 페이지를 스왑 영역으로 옮긴다
- 접근 시간이나 참조 비트를 유지하기 위해 낭비되는 메모리 공간이 많음

### 페이지 접근 시간에 기반한 구현

- 페이지에 접근한 지 가장 오래된 페이지를 교체
- 즉 , 페이지에 읽기, 쓰기, 실행과 같은 연산이 이루어진 시간을 기준으로 함
- 접근 시간을 기록
- 일반적으로 LRU 페이지 교체 알고리즘의 성능은 FIFO 페이지 교체 알고리즘보다 우수하고 최적 페이지 교체 알고리즘보다는 조금 떨어짐

### 카운터에 기반한 구현

- 시간이 아닌 카운터를 사용하여 구현
- 접근 시간을 기록하든 카운트를 하든 두 방법은 모두 추가적인 메모리 공간을 필요로 한다
    - 사용자가 사용할 수 있는 메모리 공간이 낭비됨

### 참조 비트 시프트 방식

- 각 페이지에 일정 크기의 참조 비트를 만들어서 사용
- 참조 비트의 초깃값은 0이며 페이지에 접근할 때마다 1로 바뀐다
- 참조 비트는 주기적으로 오른쪽으로 한 칸씩 이동

![](https://yansigit.github.io/posts/페이지-교체-알고리즘/Untitled%206.png)

- 참조 비트를 갱신하다가 대상 페이지를 선정할 필요가 있으면 참조 비트 중 가장 작은 값을 대상 페이지로 선정
- 참조한 횟수가 아닌 참조한 시간을 기준으로 대상 페이지 선정
- 참조 비트를 위한 작지 않은 공간이 낭비됨

## LFU 페이지 교체 알고리즘

![](https://yansigit.github.io/posts/페이지-교체-알고리즘/Untitled%207.png)

- 최소 빈도 사용 알고리즘
- 페이지가 몇 번 사용되었는지를 기준으로 대상 페이지 선정
- 현재 프레임에 있는 페이지마다 그동안 사용된 횟수를 세어 횟수가 가장 적은 페이지를 스왑 영역으로 옮긴다
- 처음 메모리에 올라온 페이지의 사용 빈도가 1이고, 페이지가 사용될 때마다 하나씩 증가
- LRU와 LFU 두 알고리즘의 성능은 비슷
    - 둘 다 FIFO 보다는 우수
- 페이지 접근 횟수를 표시하는데 추가 공간이 필요하여 그만큼 메모리가 낭비 됨

## NUR 페이지 교체 알고리즘

![](https://yansigit.github.io/posts/페이지-교체-알고리즘/Untitled%209.png)

- 최근 미사용 페이지 교체 알고리즘
- LRU, LFU와 성능이 거의 비슷하면서도 불필요한 공간 낭비 문제를 해결
- 추가 비트 2개만을 이용하여 미래 추정
    - **참조 비트:** 페이지에 접근하면 1이 된다
    - **변경 비트:** 페이지가 변경되면 1이 된다
- 모든 페이지의 초기 상태는 (0, 0)
    - 접근 발생: (1, 0)
    - 변경 발생: (0, 1)
    - 두 가지 모두 발생: (1, 1)
- 대상 페이지 선정할 때는 (0, 0), (0, 1), (1, 0), (1, 1) 중 하나 고름
- 가장 먼저 (0, 0)인 페이지를 선정
    - 접근한 적도 변경한 적도 없는 페이지를 스왑 영역으로 옮긴다
- (0, 0) → (0, 1) → (1, 0) → (1, 1) 순서로 선택
- NUR에서 우선 고려 대상은 참조 비트
    - 참조 비트가 0인 페이지를 먼저 찾고 없으면 변경 비트가 0인 페이지를 찾음
- 만약 같은 비트의 페이지가 여러 개라면 무작위로 대상 페이지 선정
- 모든 페이지의 비트가 (1, 1)일 때는 어떤 페이지가 더 자주 사용되는지 알 수 없어 정상적으로 적용할 수 없음
    - 모든 페이지 비트를 (0, 0)으로 초기화함
- LRU, LFU, NUR 모두 성능이 거의 비슷하면서 FIFO보다 우수
- NUR은 2bit만 추가하여 다른 알고리즘과 유사한 성능을 낼 뿐만 아니라 쉽게 구현할 수 있다는 장점이 있어 가장 많이 사용됨

## FIFO 변형 알고리즘

- 자주 사용하는 페이지를 고려하지 않는 FIFO의 단점을 개선한 알고리즘
- FIFO의 방식을 기본으로 하되 페이지에 접근할 때마다 순서의 변화를 준다

### 2차 기회 페이지 교체 알고리즘

![](https://yansigit.github.io/posts/페이지-교체-알고리즘/Untitled%2010.png)

- 큐 사용
- 특정 페이지에 접근하여 페이지 부재 없이 성공할 경우 해당 페이지를 큐의 맨 뒤로 이동하여 대상 페이지에서 제외
    - 성공한 페이지를 큐의 맨 뒤로 옮김으로써 기회를 한 번 더 준다
- LRU, LFU, NUR 보다 성능이 약간 낮고 FIFO보다 약간 높음
- 큐를 유지하는 비용이 높고, 페이지가 성공하면 큐의 중간에 있는 값을 뒤로 이동하는 작업이 추가됨

### 시계 알고리즘

- 2차 기회 페이지 교체 알고리즘과 유사하지만 실제 구현이 다름
- 원형 큐 사용

![](https://yansigit.github.io/posts/페이지-교체-알고리즘/Untitled%2011.png)

- 스왑 영역으로 옮길 대상 페이지를 가리키는 포인터 사용
- 이 포인터가 큐의 맨 바닥으로 내려가면 다음번에는 다시 큐의 처음을 가리킴

![](https://yansigit.github.io/posts/페이지-교체-알고리즘/Untitled%2012.png)

- 2차 기회 페이지 교체 알고리즘에 비해 각 페이지에 참조 비트가 하나씩 추가
- 메모리에 있는 페이지를 성공적으로 참조하면 0에서 1로 변경
- 시계 알고리즘의 대상 포인터는 메모리가 꽉 찰 경우 스왑 영역으로 쫓겨날 페이지를 가리킨다
- 만약 가리키는 페이지가 스왑 영역으로 쫓겨나면 대상 포인터는 밑으로 이동
    - 이 때 참조 비트가 1인 페이지는 건너뜀
        - 2차 기회 페이지 교체 알고리즘처럼 기회를 한 번 더 주기 위해
        - 대상에서 제외되는 경우는 단 한번 뿐
        - 한 바퀴 돌아 대상 포인터가 오면 제외하지 않기 위해 건너뛸 때 0으로 바꿔놓는다
    - 바닥에 도착하면 다시 메모리의 상단으로 이동
- 대상 포인터와 각 페이지당 참조 비트 하나만 추가하면 되기 때문에 NUR 알고리즘보다 추가 공간이 적게 들지만 알고리즘이 복잡하고 계산량이 많음

# 스레싱과 프레임 할당

- 물리 메모리에는 여러 개의 프로세스가 올라와 있음
- 물리 메모리의 공간이 충분하지 않을 경우 남아있는 프레임을 어떻게 나누어주느냐는 문제에 맞닥뜨림

## 스레싱

### 스레싱의 개념

- 물리 메모리의 용량을 늘리면 컴퓨터가 빨라진다
- 메모리가 꽉 찬 후에는 새로운 프로그램을 메모리에 올리기 위해 기존 프로그램을 스왑 영역으로 옮기는 횟수가 잦아짐
- **스레싱:** 하드 디스크의 입출력이 너무 많아져서 잦은 페이지 부재로 작업이 멈춘 것 같은 상태

### 물리 메모리의 크기와 스레싱

- 스레싱은 메모리의 크기가 일정할 경우 멀티프로그램 수와 밀접한 관계가 있다
- **멀티 프로그래밍 정도**: 동시에 실행하는 프로그램의 수
    - 멀티 프로그래밍 정도가 너무 높으면 스레싱 발생

![](https://yansigit.github.io/posts/스레싱/Untitled.png)

- 프로그램의 수가 적을 때는 CPU 사용률이 계속 증가
- 메모리가 꽉 차면 CPU가 작업하는 시간보다 스왑 영역으로 페이지를 메모리에 가져오는 작업이 빈번해져 CPU가 작업할 수 없는 상태에 이름
    - 이러한 상태를 **스레싱 발생 지점**이라고 한다
- 컴퓨터는 운영체제를 포함하여 많은 프로그램을 동시에 실행하는데, 자주 사용하는 프로세스가 필요로 하는 메모리보다 물리 메모리가 작다면 스레싱 발생 지점에 빨리 도달하여 컴퓨터가 전체적으로 느려짐
    - 따라서 물리 메모리의 크기를 늘리면 스레싱 발생 지점이 늦춰져서 프로세스를 원할하게 실행 가능
- 물리 메모리가 작업을 하는 데 충분한 크기가 되면 그 이후에는 크기를 늘려도 작업 속도에 영향을 미치지 않는다

### 스레싱과 프레임 할당

- 실행 중인 여러 프로세스에 프레임을 얼마나 나누어 주느냐에 따라 시스템의 성능이 달라짐
- 정적 할당과 동적 할당으로 구분

## 정적 할당

- 프로세스 실행 초기에 프레임을 나누어 준 후 그 크기를 고정

### 균등 할당 방식

- 프로세스의 크기와 상관없이 사용 가능한 프레임을 모든 프로세스에 동일하게 할당
- 크기가 큰 프로세스의 경우 필요한 만큼 프레임을 할당받지 못하기 때문에 페이지 부재가 빈번하게 발생
- 크기가 작은 프로세스의 경우 메모리가 낭비

### 비례 할당

- 프로세스의 크기에 비례하여 프레임 할당
- 고정 할당 보다 좀 더 현실적인 방식이지만 두 가지 문제가 있음
- 프로세스가 실행 중에 필요로 하는 프레임을 유동적으로 반영하지 못함
    - 아무리 작은 프로세스라도 실행 중에 많은 메모리를 필요로 하는 경우가 있지만, 실행되면서 필요로 하는 프레임을 유동적으로 반영하지 못함
- 사용하지 않을 메모리를 처음부터 미리 확보하여 공간을 낭비
    - 큰 프로세스를 실행하면서 당장 필요 없는 프레임을 미리 할당해놓기 때문에 낭비

## 동적 할당

- 시시각각 변하는 요청을 수용하는 방식

### 작업집합 모델

- 지역성 이론을 바탕으로 한다
- 가장 최근에 접근한 프레임이 이후에도 또 참조될 가능성이 높다는 가정에서 출발
- 최근 일정 시간 동안 참조된 페이지들을 집합으로 만들고, 이 집합에 있는 페이지들을 물리 메모리에 유지하여 프로세스의 실행을 돕는다
- 작업집합 크기: 작업집합 모델에서 물리 메모리에 유지할 페이지의 크기
    - 작업집합에 들어갈 최대 페이지의 수
    - 얼마나 자주 작업집합을 갱신할 것인지도 의미
        - 크기가 5라면 페이지에 다섯 번 접근할 때마다 작업 집합 갱신
- 작업집합 윈도우: 작업 집합에 포함되는 페이지의 범위
    - 현재 시점에 최대 어느 범위까지의 페이지를 살펴볼 것인가를 결정
    - 현재 시점부터 시간적으로 가까운 페이지부터 삽입
- 작업집합 윈도우의 크기에 따라 프로세스의 실행 성능이 달라짐
    - 작업 집합 윈도우를 너무 크게 잡으면 필요 없는 페이지가 메모리에 남아서 다른 프로세스에 영향을 미친다
    - 윈도우를 너무 작게 잡으면 필요한 페이지가 스왑 영역으로 옮겨져서 프로세스의 성능이 떨어진다

### 페이지 부재 빈도

- 작업집합 모델의 경우 충분한 페이지를 할당하지 않으면 작업집합에 있는 페이지를 물리 메모리에 유지하기가 힘들다
- 작업집합 모델에서는 어떤 프레임을 물리 메모리에 유지해야하는지 알 수 있지만, 프로세스에 프레임을 얼마나 할당해야 하는지는 알 수 없다
    - 프로세스의 성능을 높이는 방법이지만 스레싱 문제를 해결하지는 못함
- 프로세스가 필요로 하는 페이지의 양을 동적으로 결정하는 방법 중 페이지 부재 빈도를 이용하는 것이 있음
- 페이지 부재 횟수를 기록하여 페이지 부재 비율을 계산
- 페이지 부재 비율이 상한선을 초과하면 할당한 프레임이 적다는 것을 의미
    - 프레임을 추가하여 늘린다
- 반대로 페이지 부재 비율이 하한선 밑으로 내려가면 메모리가 낭비된다는 것을 의미
    - 할당한 프레임 회수
- 프로세스가 처음 시작될 때는 할당량을 예측하기 어렵다
    - 프로세스를 실행하면서 추가적으로 페이지를 할당하거나 회수하여 적정 페이지 할당량을 조절
